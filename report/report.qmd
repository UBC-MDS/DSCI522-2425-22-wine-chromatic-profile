---
title: Wine Chromatic Profile Prediction Project
author: "Farhan Faisal, Daria Khon, Adrian Leung, Zhiwei Zhang"
date: "2024/12/07"
format:
  html:
    toc: true
    toc-depth: 2
    embed-resources: true
    fig-numbering: true
    tbl-numbering: true
  pdf:
    toc: true
    toc-depth: 2
    fig-numbering: true
    tbl-numbering: true
embed-resources: true
editor: source
bibliography: references.bib
jupyter: python3
execute:
  echo: false
  warning: false
---

```{python}
import pickle
import pandas as pd 
import numpy as np 
from tabulate import tabulate
from IPython.display import Markdown, display
```

```{python}
# loading data 
wine_train = pd.read_csv("../data/proc/wine_train.csv")
wine_test = pd.read_csv("../data/proc/wine_test.csv")
```

```{python}
info_df = pd.read_csv("../results/tables/feature_datatypes.csv")

summary_df = pd.read_csv("../results/tables/summary_statistics.csv")
```

```{python}
with open("../results/models/wine_pipeline.pickle", "rb") as file:
    pipe = pickle.load(file)

# Running cross validation on default model
cross_validation_results = pd.read_csv("../results/tables/cross_validation.csv").rename(
    columns={"Unnamed: 0": "Scoring Metric"}
)

# Hyperparameter optimization
with open("../results/models/wine_random_search.pickle", "rb") as file:
    random_search = pickle.load(file)

random_search_results = pd.read_csv("../results/tables/random_search.csv")

best_params = random_search.best_params_["logisticregression__C"]
```

```{python}
X_test = wine_test.drop(columns = ["color"])
y_test = wine_test["color"]
best_model_accuracy = random_search.score(X_test, y_test)
```

```{python}
test_results = pd.read_csv("../results/tables/test_scores.csv")
test_accuracy = round(float(test_results["accuracy"]), 3)
test_precision = round(float(test_results["precision"]), 3)
test_recall = round(float(test_results["recall"]), 3)
test_f1 = round(float(test_results["F1 score"]), 3)
```

------------------------------------------------------------------------

## Summary

In this project, we developed a machine learning model to predict the color of wine (red or white) using its physiochemical properties such as acidity, pH, sugar content, and alcohol level. A logistic regression model with balanced class weights was implemented and optimized through hyperparameter tuning. The final model performed exceptionally well, achieving an accuracy of `{python} round(best_model_accuracy, 2)` on unseen test data. The precision-recall analysis indicated high precision and recall scores (above `{python} round(test_recall, 2) - 0.01`), further corroborated by the confusion matrix, which showed minimal misclassifications.

While the model demonstrated strong predictive accuracy, the near-perfect results raise potential concerns about overfitting, suggesting further evaluation on truly unseen data is necessary. This work emphasizes the potential for data-driven tools to optimize wine classification processes, offering a scalable and efficient approach for the wine industry.

------------------------------------------------------------------------

## Introduction

Wine classification plays a crucial role in both production and quality assessment, yet traditional methods often rely on subjective evaluations by experts. Therefore, this project seeks to answer **whether we accurately predict the color of wine using its physiochemical properties**.

Developing a machine learning model for wine classification has several advantages. For winemakers, it could provide a scalable method for analyzing large datasets, identifying trends, and optimizing production processes. For consumers and retailers, it could serve as a tool to verify wine characteristics without requiring advanced laboratory equipment. Through this project, we aim to contribute to the industry's adoption of data-driven approaches, enabling efficient, reproducible, and cost-effective methods for wine analysis.

------------------------------------------------------------------------

## Methods

### Data

The dataset for this project is sourced from the UCI Machine Learning Repository [@dua2017uci] and focuses on wines from the Vinho Verde region in Portugal. It includes 11 physiochemical attributes, such as fixed acidity, volatile acidity, pH, and alcohol content, collected from 1,599 red wine samples and 4,898 white wine samples.

### Validation

We conducted several validation checks on our dataset, including assessments for duplicates, correct data types, and missing values, most of which passed successfully. However, the outlier check flagged a few variables with potential outliers. To keep the analysis straightforward, we chose not to remove these outliers for this iteration. Future iterations could explore handling these outliers more thoroughly to refine the analysis.

### Analysis

The logistic regression algorithm was used to build a classification model to predict whether a wine sample is red or white (as defined by the `color` column in the dataset). All 11 physiochemical features in the dataset, including fixed acidity, volatile acidity, pH, and alcohol content, were utilized for model training. The dataset was split into 70% for the training set and 30% for the test set.

Preprocessing steps included removing duplicate entries, ordinal encoding for the `quality` feature, and standardizing all numeric features to ensure uniform scaling. A randomized search with 10-fold cross-validation was conducted, using F1 as the scoring metric, to fine-tune the regularization parameter (`C`). This process helped minimize classification bias and maximize accuracy while identifying the optimal model. Balanced class weights were employed to address potential class imbalances in the dataset.

The Python programming language [@python3reference] and the following libraries were utilized for the analysis: NumPy [@harris2020numpy] for numerical computations, Pandas [@mckinney2010pandas] for data manipulation, Altair [@vanderplas2018altair] for visualization, and scikit-learn [@pedregosa2011scikit] for model development and evaluation. The complete analysis code is available on GitHub: <https://github.com/UBC-MDS/DSCI522-2425-22-wine-quality.git>.

------------------------------------------------------------------------

## Results

To evaluate the usefulness of each feature in predicting wine color, we visualized their distributions in the training dataset, color-coded by class (@fig-feat-dist).

The feature distributions (@fig-feat-dist) reveals significant differences between red and white wines across multiple features. For instance, red wines generally exhibit higher levels of volatile acidity, citric acid, and chlorides, while white wines tend to have higher residual sugar, free sulfur dioxide, and total sulfur dioxide. Alcohol content shows a near-normal distribution for both wine types, with white wines displaying a broader range and slightly higher peaks at lower alcohol levels. Interestingly, alcohol is positively correlated with wine quality, which, along with pH (lower for red wines), might plays a key role in determining the color of wines. Sulphates shows left skewed shape, with red wines showing slightly higher concentrations.

While most predictors showed some overlap, notable differences were observed in their central tendencies and spreads. Features like wine quality and residual sugar exhibited less distinction between classes, but we retained them, anticipating that their interactions with other features might enhance predictive power.

We also examined multicollinearity among predictors (@fig-feat-cor), initially identifying high correlations between `alcohol and quality`, as well as `total sulfur dioxide and free sulfur dioxide`. A closer inspection of other features revealed moderate correlations between `density and residual sugar`, reflecting the physical influence of sugar content on the density of wine. Similarly, `sulphates and chlorides` displayed a moderate positive correlation, potentially due to their combined impact on wine preservation and stability. Furthermore, `volatile acidity and quality` showed a negative correlation , aligning with the perception that high levels of volatile acidity can degrade the sensory appeal of wine.

However, further validation using Deepchecks confirmed that none of these correlations exceeded the threshold of 0.8. As a result, all features were retained in the model to leverage potential interactions and maximize predictive insights. By including all predictors, the model is better positioned to capture both individual and joint effects of features, leading to a more comprehensive understanding of the factors influencing wine quality.

![Distribution of Features per Target Class](../results/figures/feature_densities_by_class.png){#fig-feat-dist}

![Correlation between Wine Color Prediction Features](../results/figures/feature_correlation.png){#fig-feat-cor}

```{python}
# #| label: tbl-cross-val
# #| tbl-cap: Cross Validation Results
# Markdown(cross_validation_results.to_markdown())
```

We employed a logistic regression model for our classification task, utilizing randomized search with 10 iterations for hyperparameter optimization. The primary goal was to determine the best regularization parameter (`C`), which was found to be `{python} round(best_params, 2)`, to maximize predictive performance. To evaluate model performance during the search, we used the F1 score (with "red" as the positive class) as our scoring metric. Cross validation results using the best model is shown in @tbl-random-search.

```{python}
#| label: tbl-random-search
#| tbl-cap: Random Search Best Model Cross-Validation Results
Markdown(cross_validation_results.to_markdown())
```

```{python}
target_drift_score = pd.read_csv("../results/tables/drift_score.csv").iloc[0, 0]
```

Before evaluating model performance on the test set, we validated that the target distributions between the training and test sets were comparable using a prediction drift check. The validation was successful, with a low Prediction Drift Score of `{python} round(target_drift_score, 3)`, indicating that the model's predictions on both datasets are consistent and align with the expected target distribution.

Finally, we evaluated the model on the test set (@tbl-test-results). We also generated a confusion matrix (@fig-confusion) and a precision-recall (PR) (@fig-pr) curve to summarize the results.

```{python}
#| label: tbl-test-results
#| tbl-cap: Test Set Results
Markdown(test_results.to_markdown())
```

![Confusion Matric](../results/figures/confusion_matrix.png){#fig-confusion}

![Precision Recall Curve](../results/figures/pr_curve.png){#fig-pr}

------------------------------------------------------------------------

## Discussion

Our model performs exceptionally well in predicting the colors of the wines as the model achieved an impressive test accuracy of `{python} round(test_accuracy, 3)`. It fits our goal of accurately classifying a wine color, whether it be red or white, without human judgement. This can serve as a reliable and efficient algorithm for wine analysis as long as we have sufficient information of the wine.

Based on the information from (@fig-confusion) and (@fig-pr), the added insights include that the model achieves excellent classification performance for wine color prediction. From the confusion matrix (@fig-confusion), it is evident that the number of false positives (predicted red but actually white) and false negatives (predicted white but actually red) is minimal.

The precision-recall (PR) curve (@fig-pr) further demonstrates the model's robust performance across various thresholds (AP = 0.99), supported by a high test precision of `{python} test_precision` and test recall of `{python} test_recall`. With an AP score of 0.99, the model exhibits near-perfect precision and recall balance. This indicates that at most thresholds, the model maintains high precision while effectively capturing almost all true positive cases, minimizing false negatives. These metrics jointly indicate that the model is highly effective at differentiating between wine colors.

These near-perfect results on the test data exceeded our expectations, as we anticipated more variability in performance, particularly with recall and precision as we would expect a larger trade-off. With both recall and precision scores exceeding `{python} round(test_recall, 2) - 0.01`, we can conclude that the trade-off between both scores are surprisingly minimal as the model is very reliable on predicting the correct color of the wine.

### Limitations

However, while these high scores suggest the model is likely to perform well on new data, they also raise concerns about potential overfitting. The model's unusually exceptional performance on both the training and test sets may suggest a possible limited generalizability on truly unseen data. This will warrant further investigation and evaluation on new data to ensure robustness.

Moreover, the logistic regression model assumes that there is no multicolinearity within the features and the data is linearly separable. By using this model, we are ignoring the possibility that features of a wine can be dependent with one another and its subsequent effect on the wine color prediction. Also, we cannot be completely certain that all newly introduced wine data can be well separated by the linear decision rule set by the model. In fact, the existing errors from the confusion matrix (@fig-confusion) show that there are possible outliers that are not linearly separable by our model. Thus, human supervision over the model performance on wine analysis is still necessary since our model can still make mistakes over time.

It is crucial to comprehend how and where our model fails on the prediction. As the model has exceptional scores on the test data, we should pay even more attention to the actual errors since there might be hidden physiochemical rules in those anomalous wine data that the model fails to figure out. Thus, when we spot an error in predicting the wine color from the model in the future, we should try interpreting the feature importances by using tools like SHAP plots to investigate which properties of the wine cause the anomaly. This can help us understand what makes the wine an outlier and lead us to new insights on how the physiochemical composition of a wine determines its chromatic profile.

------------------------------------------------------------------------

## References
